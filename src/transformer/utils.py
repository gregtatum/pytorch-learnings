from os import path
from utils.data_loader import Tokens


data_path = path.abspath(path.join(path.dirname(__file__), "../data"))


class SentenceProcessor:
    """
    Prepares source and target sentences for the Transformer model
    """

    def __init__(self, tokens: Tokens, max_seq_length: int) -> None:
        self.tokens = tokens
        self.source_eos = tokens.target.piece_to_id("</s>")
        self.target_bos = tokens.target.piece_to_id("<s>")
        self.target_eos = tokens.target.piece_to_id("</s>")
        self.max_seq_length = max_seq_length

    def zero_pad(self, list: list[int]) -> list[int]:
        """Ensures the sentence is zero padded to the correct tensor size."""
        if len(list) > self.max_seq_length:
            list = list[: self.max_seq_length]
        while len(list) < self.max_seq_length:
            list.append(0)
        return list

    def prep_source_sentence(self, sentence: str) -> list[int]:
        """Source sentences only need the eos, for both training and inference."""
        list = self.tokens.source.encode_as_ids(sentence)
        list.append(self.source_eos)
        return self.zero_pad(list)

    def prep_training_target_sentence(self, sentence: str) -> list[int]:
        """Target sentences need both the bos eos for training."""
        list = self.tokens.target.encode_as_ids(sentence)
        list.insert(0, self.target_bos)
        list.append(self.target_eos)
        return self.zero_pad(list)

    def prep_inference_target_sentence(self, sentence: str) -> list[int]:
        """Inference sentences need to start with bos. The eos will be generated by the
        inferences step"""
        list = self.tokens.target.encode_as_ids(sentence)
        list.insert(0, self.target_bos)
        return self.zero_pad(list)
